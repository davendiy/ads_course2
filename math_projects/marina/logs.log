2019-05-05 14:03:23,064 STARTED
2019-05-05 14:03:27,666 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 14:03:28,783 PASSWORD CHECKED
2019-05-05 14:03:28,790 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 14:03:30,219 session id: 56352
2019-05-05 14:03:30,220 user_id: 1
2019-05-05 14:03:34,173 session id: 56352
2019-05-05 14:03:34,173 user_id: 1
2019-05-05 14:03:34,174 [Errno 2] No such file or directory: 'uploads/android_android_zelnyy_kamni_ryukzak_30945_1366x768.jpg'
Traceback (most recent call last):
  File "/files/univer/python/course2/math_projects/marina/cgi_bin/add.py", line 36, in <module>
    with open(uploaded_file_path, 'wb') as fout:
FileNotFoundError: [Errno 2] No such file or directory: 'uploads/android_android_zelnyy_kamni_ryukzak_30945_1366x768.jpg'
2019-05-05 15:19:16,833 STARTED
2019-05-05 15:19:20,161 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:19:21,280 PASSWORD CHECKED
2019-05-05 15:19:21,338 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:19:24,624 session id: 41490
2019-05-05 15:19:24,624 user_id: 1
2019-05-05 15:19:28,303 session id: 41490
2019-05-05 15:19:28,303 user_id: 1
2019-05-05 15:19:28,325 params before substitution: {'Name': 'Name', 'Category_id': '', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/04119_hautespyrenees_2880x1800.jpg', 'Price': 'Price'}
2019-05-05 15:19:28,327 params after substitution: {'Name': 'Name', 'Category_id': 1, 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/04119_hautespyrenees_2880x1800.jpg', 'Price': 'Price'}
2019-05-05 15:19:31,155 session id: 41490
2019-05-05 15:19:31,156 user_id: 1
2019-05-05 15:19:31,159 data for home page: [{'Id': 1, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '03962_centralpark_2880x1800.jpg', 'Price': 1000}, {'Id': 2, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '03962_centralpark_2880x1800.jpg', 'Price': 1000}, {'Id': 3, 'Name': 'Test', 'Category_id': '2', 'Description': 'test description', 'Characteristics': 'test characteristics', 'Photo': '04087_riomaggioreatsunset_2880x1800.jpg', 'Price': 1000}, {'Id': 4, 'Name': 'test item2', 'Category_id': '3', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '', 'Price': 'Price'}, {'Id': 5, 'Name': 'test item3', 'Category_id': '2', 'Description': 'slkdkjfsldkjflskdjflskdjfflkjflksdjflskjfdlskjdflskdjflksdjfflkjsgklasdkjhglkdjhglsakjdhglasdflkashddkflasdf', 'Characteristics': 'etsdsjfkjshdfkjalsfkjsdjghskdjfhalksfjsldghs', 'Photo': '04119_hautespyrenees_2880x1800.jpg', 'Price': 12312323489234}, {'Id': 6, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '', 'Price': 'Price'}, {'Id': 7, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '', 'Price': 'Price'}, {'Id': 8, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '03962_centralpark_2880x1800.jpg', 'Price': 'Price'}, {'Id': 9, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '04087_riomaggioreatsunset_2880x1800.jpg', 'Price': 'Price'}, {'Id': 10, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '04087_riomaggioreatsunset_2880x1800.jpg', 'Price': 'Price'}, {'Id': 11, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/04119_hautespyrenees_2880x1800.jpg', 'Price': 'Price'}]
2019-05-05 15:19:31,163 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:20:55,760 STARTED
2019-05-05 15:20:59,683 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:21:00,807 PASSWORD CHECKED
2019-05-05 15:21:00,814 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:21:33,715 STARTED
2019-05-05 15:21:36,524 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:21:37,649 PASSWORD CHECKED
2019-05-05 15:21:37,655 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:22:53,630 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:22:54,761 PASSWORD CHECKED
2019-05-05 15:22:54,767 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:23:06,062 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:23:07,190 PASSWORD CHECKED
2019-05-05 15:23:07,196 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:24:06,438 STARTED
2019-05-05 15:24:11,080 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:24:12,209 PASSWORD CHECKED
2019-05-05 15:24:12,216 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:25:11,410 STARTED
2019-05-05 15:25:16,475 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:25:17,593 PASSWORD CHECKED
2019-05-05 15:25:17,599 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:25:22,372 session id: 94161
2019-05-05 15:25:22,372 user_id: 1
2019-05-05 15:25:57,427 session id: 94161
2019-05-05 15:25:57,427 user_id: 1
2019-05-05 15:25:57,428 params before substitution: {'Name': 'test item', 'Category_id': '', 'Description': 'this is just for test and no more', 'Characteristics': 'some very long text lsdfjlsdjflsdjf', 'Photo': '', 'Price': 'Price'}
2019-05-05 15:25:57,429 params after substitution: {'Name': 'test item', 'Category_id': 2, 'Description': 'this is just for test and no more', 'Characteristics': 'some very long text lsdfjlsdjflsdjf', 'Photo': '', 'Price': 'Price'}
2019-05-05 15:26:06,052 session id: 94161
2019-05-05 15:26:06,052 user_id: 1
2019-05-05 15:26:06,054 data for home page: [{'Id': 12, 'Name': 'test item', 'Category_id': '2', 'Description': 'this is just for test and no more', 'Characteristics': 'some very long text lsdfjlsdjflsdjf', 'Photo': '', 'Price': 'Price'}]
2019-05-05 15:26:06,056 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:32:41,224 STARTED
2019-05-05 15:32:45,277 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:32:46,396 PASSWORD CHECKED
2019-05-05 15:32:46,404 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:40:37,545 STARTED
2019-05-05 15:40:41,833 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:40:42,949 PASSWORD CHECKED
2019-05-05 15:40:42,956 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:40:46,155 session id: 15705
2019-05-05 15:40:46,156 user_id: 1
2019-05-05 15:42:37,030 STARTED
2019-05-05 15:42:58,967 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:43:00,094 PASSWORD CHECKED
2019-05-05 15:43:00,099 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:43:09,318 session id: 51031
2019-05-05 15:43:09,318 user_id: 1
2019-05-05 15:55:25,759 STARTED
2019-05-05 15:55:30,257 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:55:31,384 PASSWORD CHECKED
2019-05-05 15:55:31,390 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:55:34,414 session id: 79025
2019-05-05 15:55:34,414 user_id: 1
2019-05-05 15:56:51,035 session id: 79025
2019-05-05 15:56:51,035 user_id: 1
2019-05-05 15:56:53,357 session id: 79025
2019-05-05 15:56:53,357 user_id: 1
2019-05-05 15:56:53,359 data for home page: [{'Id': 12, 'Name': 'test item', 'Category_id': '2', 'Description': 'this is just for test and no more', 'Characteristics': 'some very long text lsdfjlsdjflsdjf', 'Photo': '', 'Price': 'Price'}]
2019-05-05 15:56:53,361 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:57:03,803 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:57:10,158 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:57:14,098 session id: 79025
2019-05-05 15:57:14,098 user_id: 1
2019-05-05 15:57:56,711 session id: 79025
2019-05-05 15:57:56,711 user_id: 1
2019-05-05 15:57:56,768 params before substitution: {'Name': 'Test', 'Category_id': '', 'Description': 'sldfkjsldfkjalskdjfla', 'Characteristics': 'lskdjflaskjdflaksdjfla', 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': '1000'}
2019-05-05 15:57:57,342 params after substitution: {'Name': 'Test', 'Category_id': 4, 'Description': 'sldfkjsldfkjalskdjfla', 'Characteristics': 'lskdjflaskjdflaksdjfla', 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': '1000'}
2019-05-05 15:57:58,756 session id: 79025
2019-05-05 15:57:58,756 user_id: 1
2019-05-05 15:57:58,759 data for home page: [{'Id': 12, 'Name': 'test item', 'Category_id': '2', 'Description': 'this is just for test and no more', 'Characteristics': 'some very long text lsdfjlsdjflsdjf', 'Photo': '', 'Price': 'Price'}, {'Id': 13, 'Name': 'Test', 'Category_id': '4', 'Description': 'sldfkjsldfkjalskdjfla', 'Characteristics': 'lskdjflaskjdflaksdjfla', 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}]
2019-05-05 15:57:58,761 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-05 15:58:43,113 STARTED
2019-05-05 15:58:45,847 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:58:46,967 PASSWORD CHECKED
2019-05-05 15:58:46,974 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-05 15:58:49,197 session id: 58996
2019-05-05 15:58:49,197 user_id: 1
2019-05-05 15:59:46,027 session id: 58996
2019-05-05 15:59:46,027 user_id: 1
2019-05-05 15:59:46,089 params before substitution: {'Name': 'test item', 'Category_id': '', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': '1000'}
2019-05-05 15:59:46,091 params after substitution: {'Name': 'test item', 'Category_id': 2, 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': '1000'}
2019-05-05 15:59:48,596 session id: 58996
2019-05-05 15:59:48,597 user_id: 1
2019-05-05 15:59:48,600 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}]
2019-05-05 15:59:48,602 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-05 16:00:14,293 session id: 58996
2019-05-05 16:00:14,293 user_id: 1
2019-05-05 16:00:14,295 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}]
2019-05-05 16:00:14,298 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-05 16:00:24,693 session id: 58996
2019-05-05 16:00:24,693 user_id: 1
2019-05-05 16:00:24,697 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}]
2019-05-05 16:00:24,699 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-05 16:00:57,709 session id: 58996
2019-05-05 16:00:57,709 user_id: 1
2019-05-05 16:01:20,548 session id: 58996
2019-05-05 16:01:20,548 user_id: 1
2019-05-05 16:01:20,560 params before substitution: {'Name': 'test item2', 'Category_id': '', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': '10000'}
2019-05-05 16:01:20,561 params after substitution: {'Name': 'test item2', 'Category_id': 2, 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': '10000'}
2019-05-05 16:01:22,309 session id: 58996
2019-05-05 16:01:22,309 user_id: 1
2019-05-05 16:01:22,313 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-05 16:01:22,315 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 16:40:51,451 STARTED
2019-05-07 16:40:57,060 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-07 16:40:58,251 PASSWORD CHECKED
2019-05-07 16:40:58,257 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 17:14:26,561 STARTED
2019-05-07 17:14:37,288 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_up', 'Sign up')])
2019-05-07 17:15:08,884 FieldStorage(None, None, [MiniFieldStorage('login', 'test user'), MiniFieldStorage('password', 'test'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-07 17:15:10,001 PASSWORD CHECKED
2019-05-07 17:15:10,014 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 17:16:40,067 FieldStorage(None, None, [MiniFieldStorage('login', 'test user'), MiniFieldStorage('password', 'test'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-07 17:16:41,255 PASSWORD CHECKED
2019-05-07 17:16:41,260 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 17:16:45,153 session id: 83583
2019-05-07 17:16:45,153 user_id: 2
2019-05-07 17:16:45,156 data for cart page: []
2019-05-07 17:16:45,158 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 17:16:50,563 session id: 83583
2019-05-07 17:16:50,564 user_id: 2
2019-05-07 17:16:50,567 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-07 17:16:50,569 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 17:16:53,128 session id: 83583
2019-05-07 17:16:53,128 user_id: 2
2019-05-07 17:16:53,131 data for cart page: []
2019-05-07 17:16:53,133 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 17:16:55,753 session id: 83583
2019-05-07 17:16:55,754 user_id: 2
2019-05-07 17:16:55,758 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-07 17:16:55,761 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 17:17:30,272 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-07 17:17:31,393 PASSWORD CHECKED
2019-05-07 17:17:31,400 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 17:19:10,002 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-07 17:19:11,128 PASSWORD CHECKED
2019-05-07 17:19:11,135 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 17:19:21,627 FieldStorage(None, None, [MiniFieldStorage('login', 'test user'), MiniFieldStorage('password', 'test'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-07 17:19:22,746 PASSWORD CHECKED
2019-05-07 17:19:22,754 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 17:19:28,356 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 17:19:33,087 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 17:19:36,931 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 17:19:40,997 session id: 46039
2019-05-07 17:19:40,997 user_id: 2
2019-05-07 17:19:41,000 data for cart page: []
2019-05-07 17:19:41,002 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 17:19:43,649 session id: 46039
2019-05-07 17:19:43,649 user_id: 2
2019-05-07 17:19:43,652 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-07 17:19:43,654 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-07 17:20:31,621 FieldStorage(None, None, [MiniFieldStorage('login', 'test user'), MiniFieldStorage('password', 'test'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-07 17:20:32,741 PASSWORD CHECKED
2019-05-07 17:20:32,748 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:06:47,181 STARTED
2019-05-08 11:06:51,278 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:06:52,404 PASSWORD CHECKED
2019-05-08 11:06:52,411 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:06:59,036 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:07:00,164 PASSWORD CHECKED
2019-05-08 11:07:00,171 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:07:19,135 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:07:20,254 PASSWORD CHECKED
2019-05-08 11:07:20,261 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:09:01,992 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:09:03,115 PASSWORD CHECKED
2019-05-08 11:09:03,121 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:09:20,651 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:09:21,795 PASSWORD CHECKED
2019-05-08 11:09:21,802 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:11:54,805 FieldStorage(None, None, [MiniFieldStorage('login', 'test user'), MiniFieldStorage('password', 'test'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:11:55,924 PASSWORD CHECKED
2019-05-08 11:11:55,930 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:13:59,753 FieldStorage(None, None, [MiniFieldStorage('login', 'test user'), MiniFieldStorage('password', 'test'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:14:00,871 PASSWORD CHECKED
2019-05-08 11:14:00,878 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:15:04,088 STARTED
2019-05-08 11:15:11,541 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:15:12,669 PASSWORD CHECKED
2019-05-08 11:15:12,673 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart">
    <input type="hidden" name="session" value="{session}">
    <input type="hidden" name="item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 11:15:12,676 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:15:50,596 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:15:51,728 PASSWORD CHECKED
2019-05-08 11:15:51,734 template button: 
2019-05-08 11:15:51,735 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:16:08,505 FieldStorage(None, None, [MiniFieldStorage('login', 'test user'), MiniFieldStorage('password', 'test'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:16:09,631 PASSWORD CHECKED
2019-05-08 11:16:09,636 template button: 
2019-05-08 11:16:09,638 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:17:21,232 STARTED
2019-05-08 11:17:41,432 FieldStorage(None, None, [MiniFieldStorage('login', 'test user'), MiniFieldStorage('password', 'test'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:17:42,587 PASSWORD CHECKED
2019-05-08 11:17:42,593 template button: 
2019-05-08 11:17:42,594 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:18:04,191 STARTED
2019-05-08 11:19:26,518 STARTED
2019-05-08 11:19:30,178 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:19:31,299 PASSWORD CHECKED
2019-05-08 11:19:31,303 template button: 
2019-05-08 11:19:31,305 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:19:41,614 FieldStorage(None, None, [MiniFieldStorage('login', 'test user'), MiniFieldStorage('password', 'test'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:19:42,745 PASSWORD CHECKED
2019-05-08 11:19:42,751 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart">
    <input type="hidden" name="86338" value="{86338}">
    <input type="hidden" name="item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 11:19:42,753 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:20:14,122 FieldStorage(None, None, [MiniFieldStorage('login', 'test user'), MiniFieldStorage('password', 'test'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:20:15,246 PASSWORD CHECKED
2019-05-08 11:20:15,250 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="97933" value="{97933}">
    <input type="hidden" name="item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 11:20:15,252 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:20:41,360 template button: 
2019-05-08 11:20:41,362 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:20:47,397 template button: 
2019-05-08 11:20:47,400 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:23:31,702 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="97933">
    <input type="hidden" name="item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 11:23:31,704 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:23:35,384 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="97933">
    <input type="hidden" name="item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 11:23:35,386 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:24:50,119 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="97933">
    <input type="hidden" name="item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 11:24:50,121 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:25:03,771 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="97933">
    <input type="hidden" name="item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 11:25:03,773 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:25:06,191 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="97933">
    <input type="hidden" name="item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 11:25:06,194 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:25:11,224 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="97933">
    <input type="hidden" name="item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 11:25:11,226 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:25:43,155 session id: 97933
2019-05-08 11:25:43,156 user_id: 2
2019-05-08 11:25:43,158 data for cart page: []
2019-05-08 11:25:43,159 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="97933">
    <input type="hidden" name="item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 11:25:43,160 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:25:46,779 session id: 97933
2019-05-08 11:25:46,780 user_id: 2
2019-05-08 11:25:46,782 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 11:25:46,783 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="97933">
    <input type="hidden" name="item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 11:25:46,785 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:39:08,136 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:39:09,265 PASSWORD CHECKED
2019-05-08 11:39:09,270 template button: 
2019-05-08 11:39:09,272 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:49:01,342 STARTED
2019-05-08 11:49:12,379 FieldStorage(None, None, [MiniFieldStorage('login', 'test user'), MiniFieldStorage('password', 'test'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:49:13,499 PASSWORD CHECKED
2019-05-08 11:49:13,503 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="27277" value="{27277}">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 11:49:13,505 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:50:02,226 STARTED
2019-05-08 11:50:12,379 FieldStorage(None, None, [MiniFieldStorage('login', 'test user'), MiniFieldStorage('password', 'test'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 11:50:13,505 PASSWORD CHECKED
2019-05-08 11:50:13,511 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="54447">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 11:50:13,513 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 11:50:16,203 session id: MiniFieldStorage('session', '54447')
2019-05-08 11:50:16,203 user_id: None
2019-05-08 13:43:54,304 session id: MiniFieldStorage('session', '54447')
2019-05-08 13:43:54,304 user_id: None
2019-05-08 13:44:50,513 session id: MiniFieldStorage('session', '54447')
2019-05-08 13:44:50,513 user_id: None
2019-05-08 13:44:50,513 sessions: {'54447': 2}
2019-05-08 13:45:10,809 session id: 54447
2019-05-08 13:45:10,809 user_id: 2
2019-05-08 13:45:10,809 sessions: {'54447': 2}
2019-05-08 13:45:11,021 data for cart page: [{'Item_id': 14}]
2019-05-08 13:45:11,021 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="54447">
    <input type="hidden" name="item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 13:45:11,025 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 13:50:16,508 session id: 54447
2019-05-08 13:50:16,509 user_id: 2
2019-05-08 13:50:16,509 sessions: {'54447': 2}
2019-05-08 13:50:16,736 data for cart page: [14, 14]
2019-05-08 13:50:16,736 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="54447">
    <input type="hidden" name="item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 13:50:16,739 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 13:53:08,632 session id: 54447
2019-05-08 13:53:08,633 user_id: 2
2019-05-08 13:53:08,633 sessions: {'54447': 2}
2019-05-08 13:53:08,870 data for cart page: [(14, 'test item', '2', 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'uploads/avengers_infinity_war_4k_8k_2.jpg', 1000), (14, 'test item', '2', 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'uploads/avengers_infinity_war_4k_8k_2.jpg', 1000), (14, 'test item', '2', 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'uploads/avengers_infinity_war_4k_8k_2.jpg', 1000)]
2019-05-08 13:53:08,871 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="54447">
    <input type="hidden" name="item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 13:53:08,874 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 13:54:15,364 session id: 54447
2019-05-08 13:54:15,365 user_id: 2
2019-05-08 13:54:15,365 sessions: {'54447': 2}
2019-05-08 13:54:15,577 data for cart page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}]
2019-05-08 13:54:15,578 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="54447">
    <input type="hidden" name="item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 13:54:15,580 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 13:55:32,919 session id: 54447
2019-05-08 13:55:32,920 user_id: 2
2019-05-08 13:55:32,922 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 13:55:32,922 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="54447">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 13:55:32,925 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 13:55:36,465 session id: 54447
2019-05-08 13:55:36,465 user_id: 2
2019-05-08 13:55:36,467 data for cart page: [{'Item_id': 14}, {'Item_id': 14}, {'Item_id': 14}, {'Item_id': 14}]
2019-05-08 13:55:36,468 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="54447">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 13:55:36,469 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 13:56:36,877 session id: 54447
2019-05-08 13:56:36,877 user_id: 2
2019-05-08 13:56:36,887 data for cart page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}]
2019-05-08 13:56:36,888 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="54447">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 13:56:36,890 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 13:57:19,591 session id: 54447
2019-05-08 13:57:19,592 user_id: 2
2019-05-08 13:57:19,594 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 13:57:19,595 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="54447">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 13:57:19,597 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 13:57:23,048 session id: 54447
2019-05-08 13:57:23,048 user_id: 2
2019-05-08 13:57:23,063 data for cart page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}]
2019-05-08 13:57:23,064 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="54447">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 13:57:23,067 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 13:59:12,236 session id: 27277
2019-05-08 13:59:12,236 user_id: None
2019-05-08 13:59:20,216 session id: 27277
2019-05-08 13:59:20,216 user_id: None
2019-05-08 13:59:57,772 FieldStorage(None, None, [MiniFieldStorage('login', 'test user'), MiniFieldStorage('password', 'test'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-08 13:59:58,890 PASSWORD CHECKED
2019-05-08 13:59:58,894 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 13:59:58,896 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:00:01,540 session id: 12922
2019-05-08 14:00:01,540 user_id: 2
2019-05-08 14:00:01,546 data for cart page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}]
2019-05-08 14:00:01,547 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:00:01,548 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:00:05,531 session id: 12922
2019-05-08 14:00:05,532 user_id: 2
2019-05-08 14:00:05,532 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:00:06,008 data for cart page: []
2019-05-08 14:00:06,008 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:00:06,011 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:00:09,026 session id: 12922
2019-05-08 14:00:09,026 user_id: 2
2019-05-08 14:00:09,029 data for cart page: []
2019-05-08 14:00:09,029 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:00:09,031 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:00:10,795 session id: 12922
2019-05-08 14:00:10,796 user_id: 2
2019-05-08 14:00:10,798 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:00:10,798 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 14:00:10,800 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:00:15,621 session id: 12922
2019-05-08 14:00:15,621 user_id: 2
2019-05-08 14:00:15,623 data for cart page: []
2019-05-08 14:00:15,624 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:00:15,626 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:00:16,936 session id: 12922
2019-05-08 14:00:16,937 user_id: 2
2019-05-08 14:00:16,939 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:00:16,939 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 14:00:16,941 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:00:19,742 session id: 12922
2019-05-08 14:00:19,742 user_id: 2
2019-05-08 14:00:19,742 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:00:20,199 data for cart page: [{'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:00:20,200 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:00:20,203 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:00:30,242 session id: 12922
2019-05-08 14:00:30,242 user_id: 2
2019-05-08 14:00:30,242 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:00:30,419 data for cart page: []
2019-05-08 14:00:30,419 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:00:30,422 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:01:02,673 session id: 12922
2019-05-08 14:01:02,673 user_id: 2
2019-05-08 14:01:02,676 data for cart page: []
2019-05-08 14:01:02,676 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:01:02,678 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:01:04,100 session id: 12922
2019-05-08 14:01:04,100 user_id: 2
2019-05-08 14:01:04,103 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:01:04,103 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 14:01:04,105 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:01:05,821 session id: 12922
2019-05-08 14:01:05,821 user_id: 2
2019-05-08 14:01:05,822 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:01:23,988 session id: 12922
2019-05-08 14:01:23,988 user_id: 2
2019-05-08 14:01:23,988 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:01:24,199 data for cart page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}]
2019-05-08 14:01:24,200 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:01:24,202 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:01:27,803 session id: 12922
2019-05-08 14:01:27,803 user_id: 2
2019-05-08 14:01:27,803 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:01:27,991 data for cart page: []
2019-05-08 14:01:27,992 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:01:27,993 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:01:29,752 session id: 12922
2019-05-08 14:01:29,752 user_id: 2
2019-05-08 14:01:29,755 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:01:29,755 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 14:01:29,757 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:01:31,420 session id: 12922
2019-05-08 14:01:31,420 user_id: 2
2019-05-08 14:01:31,420 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:01:31,596 data for cart page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}]
2019-05-08 14:01:31,597 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:01:31,599 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:01:33,161 session id: 12922
2019-05-08 14:01:33,161 user_id: 2
2019-05-08 14:01:33,164 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:01:33,164 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 14:01:33,167 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:01:35,261 session id: 12922
2019-05-08 14:01:35,261 user_id: 2
2019-05-08 14:01:35,261 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:01:35,440 data for cart page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:01:35,441 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:01:35,443 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:01:40,762 session id: 12922
2019-05-08 14:01:40,763 user_id: 2
2019-05-08 14:01:40,763 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:01:40,939 data for cart page: [{'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:01:40,939 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:01:40,942 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:01:42,375 session id: 12922
2019-05-08 14:01:42,376 user_id: 2
2019-05-08 14:01:42,376 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:01:42,569 data for cart page: []
2019-05-08 14:01:42,569 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:01:42,571 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:01:44,015 session id: 12922
2019-05-08 14:01:44,015 user_id: 2
2019-05-08 14:01:44,017 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:01:44,018 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 14:01:44,020 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:02:23,753 session id: 12922
2019-05-08 14:02:23,753 user_id: 2
2019-05-08 14:02:23,756 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:02:23,756 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 14:02:23,757 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:02:26,309 session id: 12922
2019-05-08 14:02:26,309 user_id: 2
2019-05-08 14:02:26,309 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:02:26,503 data for cart page: [{'Item_id': 14}]
2019-05-08 14:02:26,503 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:02:26,506 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:02:49,837 session id: 12922
2019-05-08 14:02:49,838 user_id: 2
2019-05-08 14:02:49,838 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:02:50,024 data for cart page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:02:50,025 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:02:50,028 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:03:18,393 session id: 12922
2019-05-08 14:03:18,394 user_id: 2
2019-05-08 14:03:18,396 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:03:18,397 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 14:03:18,400 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:03:20,354 session id: 12922
2019-05-08 14:03:20,355 user_id: 2
2019-05-08 14:03:20,355 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:03:20,601 data for cart page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:03:20,602 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:03:20,604 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:03:30,719 session id: 12922
2019-05-08 14:03:30,719 user_id: 2
2019-05-08 14:03:30,721 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:03:30,722 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 14:03:30,724 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:03:32,301 session id: 12922
2019-05-08 14:03:32,301 user_id: 2
2019-05-08 14:03:32,301 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:03:32,487 data for cart page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:03:32,488 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 14:03:32,490 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:03:33,977 session id: 12922
2019-05-08 14:03:33,977 user_id: 2
2019-05-08 14:03:33,977 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:03:34,156 data for cart page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:03:34,156 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 14:03:34,159 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:03:35,984 session id: 12922
2019-05-08 14:03:35,984 user_id: 2
2019-05-08 14:03:35,993 data for cart page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}, {'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:03:35,996 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:03:35,998 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:03:40,139 session id: 12922
2019-05-08 14:03:40,139 user_id: 2
2019-05-08 14:03:40,139 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:03:40,326 data for cart page: [{'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:03:40,327 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:03:40,329 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:03:41,926 session id: 12922
2019-05-08 14:03:41,926 user_id: 2
2019-05-08 14:03:41,926 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:03:42,097 data for cart page: []
2019-05-08 14:03:42,098 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-08 14:03:42,100 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:03:43,911 session id: 12922
2019-05-08 14:03:43,911 user_id: 2
2019-05-08 14:03:43,914 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-08 14:03:43,914 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 14:03:43,916 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-08 14:03:52,848 sessions: {'54447': 2, '12922': 2}
2019-05-08 14:03:52,851 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="12922">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-08 14:03:52,853 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-09 11:49:39,332 STARTED
2019-05-09 11:50:00,842 STARTED
2019-05-09 11:50:08,972 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-09 11:50:10,121 PASSWORD CHECKED
2019-05-09 11:50:10,160 template button: 
2019-05-09 11:50:10,192 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-09 11:50:15,903 session id: 16829
2019-05-09 11:50:15,904 user_id: 1
2019-05-09 11:51:04,945 session id: 16829
2019-05-09 11:51:04,945 user_id: 1
2019-05-09 11:51:04,973 params before substitution: {'Name': 'Some new item', 'Category_id': '', 'Description': "A proof by contradiction is a method of proving a statement by assuming the hypothesis to be true and conclusion to be false, and then deriving a contradiction. For instance, suppose we want to prove ‘If A, then B'. In proof by contradiction, we assume that A is true and B is false. We then show that such an assumption leads to a something which is known to be false, which in turn means that our initial assumption that B is false is erroneous and hence B must true. More precisely, we would have ¬B⟹False. But we know that the implication ¬B⟹False is true only when ¬B is false ( if you don’t get this, kindly look at the truth table of implication). In other words, B is true.", 'Characteristics': 'Prjoijerjlsldfsldf', 'Photo': 'uploads/linuks_sok_vindovs_belyy_pingvin_26510_1366x768.jpg', 'Price': '2320'}
2019-05-09 11:51:04,974 params after substitution: {'Name': 'Some new item', 'Category_id': 1, 'Description': "A proof by contradiction is a method of proving a statement by assuming the hypothesis to be true and conclusion to be false, and then deriving a contradiction. For instance, suppose we want to prove ‘If A, then B'. In proof by contradiction, we assume that A is true and B is false. We then show that such an assumption leads to a something which is known to be false, which in turn means that our initial assumption that B is false is erroneous and hence B must true. More precisely, we would have ¬B⟹False. But we know that the implication ¬B⟹False is true only when ¬B is false ( if you don’t get this, kindly look at the truth table of implication). In other words, B is true.", 'Characteristics': 'Prjoijerjlsldfsldf', 'Photo': 'uploads/linuks_sok_vindovs_belyy_pingvin_26510_1366x768.jpg', 'Price': '2320'}
2019-05-09 11:51:06,953 session id: 16829
2019-05-09 11:51:06,954 user_id: 1
2019-05-09 11:51:06,957 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}, {'Id': 16, 'Name': 'Some new item', 'Category_id': '1', 'Description': "A proof by contradiction is a method of proving a statement by assuming the hypothesis to be true and conclusion to be false, and then deriving a contradiction. For instance, suppose we want to prove ‘If A, then B'. In proof by contradiction, we assume that A is true and B is false. We then show that such an assumption leads to a something which is known to be false, which in turn means that our initial assumption that B is false is erroneous and hence B must true. More precisely, we would have ¬B⟹False. But we know that the implication ¬B⟹False is true only when ¬B is false ( if you don’t get this, kindly look at the truth table of implication). In other words, B is true.", 'Characteristics': 'Prjoijerjlsldfsldf', 'Photo': 'uploads/linuks_sok_vindovs_belyy_pingvin_26510_1366x768.jpg', 'Price': 2320}]
2019-05-09 11:51:06,962 template button: 
2019-05-09 11:51:06,964 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-09 11:51:11,959 session id: 16829
2019-05-09 11:51:11,959 user_id: 1
2019-05-09 11:51:11,962 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}, {'Id': 16, 'Name': 'Some new item', 'Category_id': '1', 'Description': "A proof by contradiction is a method of proving a statement by assuming the hypothesis to be true and conclusion to be false, and then deriving a contradiction. For instance, suppose we want to prove ‘If A, then B'. In proof by contradiction, we assume that A is true and B is false. We then show that such an assumption leads to a something which is known to be false, which in turn means that our initial assumption that B is false is erroneous and hence B must true. More precisely, we would have ¬B⟹False. But we know that the implication ¬B⟹False is true only when ¬B is false ( if you don’t get this, kindly look at the truth table of implication). In other words, B is true.", 'Characteristics': 'Prjoijerjlsldfsldf', 'Photo': 'uploads/linuks_sok_vindovs_belyy_pingvin_26510_1366x768.jpg', 'Price': 2320}]
2019-05-09 11:51:11,962 template button: 
2019-05-09 11:51:11,964 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-09 11:51:29,030 FieldStorage(None, None, [MiniFieldStorage('login', 'test user'), MiniFieldStorage('password', 'test'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-09 11:51:30,191 PASSWORD CHECKED
2019-05-09 11:51:30,218 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="36129">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-09 11:51:30,221 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-09 11:51:51,867 sessions: {'16829': 1, '36129': 2}
2019-05-09 11:51:51,871 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="36129">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-09 11:51:51,874 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-09 11:51:58,884 session id: 36129
2019-05-09 11:51:58,885 user_id: 2
2019-05-09 11:51:58,885 sessions: {'16829': 1, '36129': 2}
2019-05-09 11:51:59,084 data for cart page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}, {'Id': 16, 'Name': 'Some new item', 'Category_id': '1', 'Description': "A proof by contradiction is a method of proving a statement by assuming the hypothesis to be true and conclusion to be false, and then deriving a contradiction. For instance, suppose we want to prove ‘If A, then B'. In proof by contradiction, we assume that A is true and B is false. We then show that such an assumption leads to a something which is known to be false, which in turn means that our initial assumption that B is false is erroneous and hence B must true. More precisely, we would have ¬B⟹False. But we know that the implication ¬B⟹False is true only when ¬B is false ( if you don’t get this, kindly look at the truth table of implication). In other words, B is true.", 'Characteristics': 'Prjoijerjlsldfsldf', 'Photo': 'uploads/linuks_sok_vindovs_belyy_pingvin_26510_1366x768.jpg', 'Price': 2320}]
2019-05-09 11:51:59,084 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="36129">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-09 11:51:59,086 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-09 11:52:00,822 session id: 36129
2019-05-09 11:52:00,823 user_id: 2
2019-05-09 11:52:00,836 data for cart page: [{'Id': 16, 'Name': 'Some new item', 'Category_id': '1', 'Description': "A proof by contradiction is a method of proving a statement by assuming the hypothesis to be true and conclusion to be false, and then deriving a contradiction. For instance, suppose we want to prove ‘If A, then B'. In proof by contradiction, we assume that A is true and B is false. We then show that such an assumption leads to a something which is known to be false, which in turn means that our initial assumption that B is false is erroneous and hence B must true. More precisely, we would have ¬B⟹False. But we know that the implication ¬B⟹False is true only when ¬B is false ( if you don’t get this, kindly look at the truth table of implication). In other words, B is true.", 'Characteristics': 'Prjoijerjlsldfsldf', 'Photo': 'uploads/linuks_sok_vindovs_belyy_pingvin_26510_1366x768.jpg', 'Price': 2320}]
2019-05-09 11:52:00,837 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="36129">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-09 11:52:00,839 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-09 11:52:02,844 session id: 36129
2019-05-09 11:52:02,844 user_id: 2
2019-05-09 11:52:02,844 sessions: {'16829': 1, '36129': 2}
2019-05-09 11:52:03,027 data for cart page: []
2019-05-09 11:52:03,027 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Delete" value="Remove from cart" class='button'>
    <input type="hidden" name="session" value="36129">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Delete">
</form>

2019-05-09 11:52:03,029 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-09 11:52:04,586 session id: 36129
2019-05-09 11:52:04,586 user_id: 2
2019-05-09 11:52:04,589 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}, {'Id': 16, 'Name': 'Some new item', 'Category_id': '1', 'Description': "A proof by contradiction is a method of proving a statement by assuming the hypothesis to be true and conclusion to be false, and then deriving a contradiction. For instance, suppose we want to prove ‘If A, then B'. In proof by contradiction, we assume that A is true and B is false. We then show that such an assumption leads to a something which is known to be false, which in turn means that our initial assumption that B is false is erroneous and hence B must true. More precisely, we would have ¬B⟹False. But we know that the implication ¬B⟹False is true only when ¬B is false ( if you don’t get this, kindly look at the truth table of implication). In other words, B is true.", 'Characteristics': 'Prjoijerjlsldfsldf', 'Photo': 'uploads/linuks_sok_vindovs_belyy_pingvin_26510_1366x768.jpg', 'Price': 2320}]
2019-05-09 11:52:04,589 template button: 
<form method="post" action="../cgi_bin/cart.py">
    <input type="submit" name="Add2Cart" value="Add to cart" class='button'>
    <input type="hidden" name="session" value="36129">
    <input type="hidden" name="Item_id" value="{Item_id}">
    <input type="hidden" name="type" value="Add">
</form>

2019-05-09 11:52:04,591 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
