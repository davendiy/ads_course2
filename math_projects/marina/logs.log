2019-05-05 14:03:23,064 STARTED
2019-05-05 14:03:27,666 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 14:03:28,783 PASSWORD CHECKED
2019-05-05 14:03:28,790 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 14:03:30,219 session id: 56352
2019-05-05 14:03:30,220 user_id: 1
2019-05-05 14:03:34,173 session id: 56352
2019-05-05 14:03:34,173 user_id: 1
2019-05-05 14:03:34,174 [Errno 2] No such file or directory: 'uploads/android_android_zelnyy_kamni_ryukzak_30945_1366x768.jpg'
Traceback (most recent call last):
  File "/files/univer/python/course2/math_projects/marina/cgi_bin/add.py", line 36, in <module>
    with open(uploaded_file_path, 'wb') as fout:
FileNotFoundError: [Errno 2] No such file or directory: 'uploads/android_android_zelnyy_kamni_ryukzak_30945_1366x768.jpg'
2019-05-05 15:19:16,833 STARTED
2019-05-05 15:19:20,161 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:19:21,280 PASSWORD CHECKED
2019-05-05 15:19:21,338 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:19:24,624 session id: 41490
2019-05-05 15:19:24,624 user_id: 1
2019-05-05 15:19:28,303 session id: 41490
2019-05-05 15:19:28,303 user_id: 1
2019-05-05 15:19:28,325 params before substitution: {'Name': 'Name', 'Category_id': '', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/04119_hautespyrenees_2880x1800.jpg', 'Price': 'Price'}
2019-05-05 15:19:28,327 params after substitution: {'Name': 'Name', 'Category_id': 1, 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/04119_hautespyrenees_2880x1800.jpg', 'Price': 'Price'}
2019-05-05 15:19:31,155 session id: 41490
2019-05-05 15:19:31,156 user_id: 1
2019-05-05 15:19:31,159 data for home page: [{'Id': 1, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '03962_centralpark_2880x1800.jpg', 'Price': 1000}, {'Id': 2, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '03962_centralpark_2880x1800.jpg', 'Price': 1000}, {'Id': 3, 'Name': 'Test', 'Category_id': '2', 'Description': 'test description', 'Characteristics': 'test characteristics', 'Photo': '04087_riomaggioreatsunset_2880x1800.jpg', 'Price': 1000}, {'Id': 4, 'Name': 'test item2', 'Category_id': '3', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '', 'Price': 'Price'}, {'Id': 5, 'Name': 'test item3', 'Category_id': '2', 'Description': 'slkdkjfsldkjflskdjflskdjfflkjflksdjflskjfdlskjdflskdjflksdjfflkjsgklasdkjhglkdjhglsakjdhglasdflkashddkflasdf', 'Characteristics': 'etsdsjfkjshdfkjalsfkjsdjghskdjfhalksfjsldghs', 'Photo': '04119_hautespyrenees_2880x1800.jpg', 'Price': 12312323489234}, {'Id': 6, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '', 'Price': 'Price'}, {'Id': 7, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '', 'Price': 'Price'}, {'Id': 8, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '03962_centralpark_2880x1800.jpg', 'Price': 'Price'}, {'Id': 9, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '04087_riomaggioreatsunset_2880x1800.jpg', 'Price': 'Price'}, {'Id': 10, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': '04087_riomaggioreatsunset_2880x1800.jpg', 'Price': 'Price'}, {'Id': 11, 'Name': 'Name', 'Category_id': '1', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/04119_hautespyrenees_2880x1800.jpg', 'Price': 'Price'}]
2019-05-05 15:19:31,163 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:20:55,760 STARTED
2019-05-05 15:20:59,683 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:21:00,807 PASSWORD CHECKED
2019-05-05 15:21:00,814 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:21:33,715 STARTED
2019-05-05 15:21:36,524 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:21:37,649 PASSWORD CHECKED
2019-05-05 15:21:37,655 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:22:53,630 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:22:54,761 PASSWORD CHECKED
2019-05-05 15:22:54,767 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:23:06,062 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:23:07,190 PASSWORD CHECKED
2019-05-05 15:23:07,196 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:24:06,438 STARTED
2019-05-05 15:24:11,080 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:24:12,209 PASSWORD CHECKED
2019-05-05 15:24:12,216 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:25:11,410 STARTED
2019-05-05 15:25:16,475 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:25:17,593 PASSWORD CHECKED
2019-05-05 15:25:17,599 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:25:22,372 session id: 94161
2019-05-05 15:25:22,372 user_id: 1
2019-05-05 15:25:57,427 session id: 94161
2019-05-05 15:25:57,427 user_id: 1
2019-05-05 15:25:57,428 params before substitution: {'Name': 'test item', 'Category_id': '', 'Description': 'this is just for test and no more', 'Characteristics': 'some very long text lsdfjlsdjflsdjf', 'Photo': '', 'Price': 'Price'}
2019-05-05 15:25:57,429 params after substitution: {'Name': 'test item', 'Category_id': 2, 'Description': 'this is just for test and no more', 'Characteristics': 'some very long text lsdfjlsdjflsdjf', 'Photo': '', 'Price': 'Price'}
2019-05-05 15:26:06,052 session id: 94161
2019-05-05 15:26:06,052 user_id: 1
2019-05-05 15:26:06,054 data for home page: [{'Id': 12, 'Name': 'test item', 'Category_id': '2', 'Description': 'this is just for test and no more', 'Characteristics': 'some very long text lsdfjlsdjflsdjf', 'Photo': '', 'Price': 'Price'}]
2019-05-05 15:26:06,056 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:32:41,224 STARTED
2019-05-05 15:32:45,277 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:32:46,396 PASSWORD CHECKED
2019-05-05 15:32:46,404 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:40:37,545 STARTED
2019-05-05 15:40:41,833 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:40:42,949 PASSWORD CHECKED
2019-05-05 15:40:42,956 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:40:46,155 session id: 15705
2019-05-05 15:40:46,156 user_id: 1
2019-05-05 15:42:37,030 STARTED
2019-05-05 15:42:58,967 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:43:00,094 PASSWORD CHECKED
2019-05-05 15:43:00,099 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:43:09,318 session id: 51031
2019-05-05 15:43:09,318 user_id: 1
2019-05-05 15:55:25,759 STARTED
2019-05-05 15:55:30,257 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:55:31,384 PASSWORD CHECKED
2019-05-05 15:55:31,390 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:55:34,414 session id: 79025
2019-05-05 15:55:34,414 user_id: 1
2019-05-05 15:56:51,035 session id: 79025
2019-05-05 15:56:51,035 user_id: 1
2019-05-05 15:56:53,357 session id: 79025
2019-05-05 15:56:53,357 user_id: 1
2019-05-05 15:56:53,359 data for home page: [{'Id': 12, 'Name': 'test item', 'Category_id': '2', 'Description': 'this is just for test and no more', 'Characteristics': 'some very long text lsdfjlsdjflsdjf', 'Photo': '', 'Price': 'Price'}]
2019-05-05 15:56:53,361 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:57:03,803 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:57:10,158 translate: {1: 'Category', 2: 'test category', 3: 'test '}
2019-05-05 15:57:14,098 session id: 79025
2019-05-05 15:57:14,098 user_id: 1
2019-05-05 15:57:56,711 session id: 79025
2019-05-05 15:57:56,711 user_id: 1
2019-05-05 15:57:56,768 params before substitution: {'Name': 'Test', 'Category_id': '', 'Description': 'sldfkjsldfkjalskdjfla', 'Characteristics': 'lskdjflaskjdflaksdjfla', 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': '1000'}
2019-05-05 15:57:57,342 params after substitution: {'Name': 'Test', 'Category_id': 4, 'Description': 'sldfkjsldfkjalskdjfla', 'Characteristics': 'lskdjflaskjdflaksdjfla', 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': '1000'}
2019-05-05 15:57:58,756 session id: 79025
2019-05-05 15:57:58,756 user_id: 1
2019-05-05 15:57:58,759 data for home page: [{'Id': 12, 'Name': 'test item', 'Category_id': '2', 'Description': 'this is just for test and no more', 'Characteristics': 'some very long text lsdfjlsdjflsdjf', 'Photo': '', 'Price': 'Price'}, {'Id': 13, 'Name': 'Test', 'Category_id': '4', 'Description': 'sldfkjsldfkjalskdjfla', 'Characteristics': 'lskdjflaskjdflaksdjfla', 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}]
2019-05-05 15:57:58,761 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-05 15:58:43,113 STARTED
2019-05-05 15:58:45,847 FieldStorage(None, None, [MiniFieldStorage('login', 'admin'), MiniFieldStorage('password', '1234'), MiniFieldStorage('Sign_in', 'Sign in')])
2019-05-05 15:58:46,967 PASSWORD CHECKED
2019-05-05 15:58:46,974 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-05 15:58:49,197 session id: 58996
2019-05-05 15:58:49,197 user_id: 1
2019-05-05 15:59:46,027 session id: 58996
2019-05-05 15:59:46,027 user_id: 1
2019-05-05 15:59:46,089 params before substitution: {'Name': 'test item', 'Category_id': '', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': '1000'}
2019-05-05 15:59:46,091 params after substitution: {'Name': 'test item', 'Category_id': 2, 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': '1000'}
2019-05-05 15:59:48,596 session id: 58996
2019-05-05 15:59:48,597 user_id: 1
2019-05-05 15:59:48,600 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}]
2019-05-05 15:59:48,602 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-05 16:00:14,293 session id: 58996
2019-05-05 16:00:14,293 user_id: 1
2019-05-05 16:00:14,295 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}]
2019-05-05 16:00:14,298 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-05 16:00:24,693 session id: 58996
2019-05-05 16:00:24,693 user_id: 1
2019-05-05 16:00:24,697 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}]
2019-05-05 16:00:24,699 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
2019-05-05 16:00:57,709 session id: 58996
2019-05-05 16:00:57,709 user_id: 1
2019-05-05 16:01:20,548 session id: 58996
2019-05-05 16:01:20,548 user_id: 1
2019-05-05 16:01:20,560 params before substitution: {'Name': 'test item2', 'Category_id': '', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': '10000'}
2019-05-05 16:01:20,561 params after substitution: {'Name': 'test item2', 'Category_id': 2, 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': '10000'}
2019-05-05 16:01:22,309 session id: 58996
2019-05-05 16:01:22,309 user_id: 1
2019-05-05 16:01:22,313 data for home page: [{'Id': 14, 'Name': 'test item', 'Category_id': '2', 'Description': 'Some very long text from wikipedia:\r\nMathematical optimization\r\nIn terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time. This is done by defining a sequence of value functions V1, V2, ..., Vn taking y as an argument representing the state of the system at times i from 1 to n. The definition of Vn(y) is the value obtained in state y at the last time n. The values Vi at earlier times i = n −1, n − 2, ..., 2, 1 can be found by working backwards, using a recursive relationship called the Bellman equation. For i = 2, ..., n, Vi−1 at any state y is calculated from Vi by maximizing a simple function (usually the sum) of the gain from a decision at time i − 1 and the function Vi at the new state of the system if this decision is made. Since Vi has already been calculated for the needed states, the above operation yields Vi−1 for those states. Finally, V1 at the initial state of the system is the value of the optimal solution. The optimal values of the decision variables can be recovered, one by one, by tracking back the calculations already performed.\r\n\r\nControl theory\r\nIn control theory, a typical problem is to find an admissible control {\\displaystyle \\mathbf {u} ^{\\ast }} {\\displaystyle \\mathbf {u} ^{\\ast }} which causes the system {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} {\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)} to follow an admissible trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} on a continuous time interval {\\displaystyle t_{0}\\leq t\\leq t_{1}} {\\displaystyle t_{0}\\leq t\\leq t_{1}} that minimizes a cost function\r\n\r\n{\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t} {\\displaystyle J=b\\left(\\mathbf {x} (t_{1}),t_{1}\\right)+\\int _{t_{0}}^{t_{1}}f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\mathrm {d} t}\r\nThe solution to this problem is an optimal control law or policy {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)} {\\displaystyle \\mathbf {u} ^{\\ast }=h(\\mathbf {x} (t),t)}, which produces an optimal trajectory {\\displaystyle \\mathbf {x} ^{\\ast }} {\\displaystyle \\mathbf {x} ^{\\ast }} and an optimized loss function {\\displaystyle J^{\\ast }} {\\displaystyle J^{\\ast }}. The latter obeys the fundamental equation of dynamic programming:\r\n\r\n{\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}} {\\displaystyle -J_{t}^{\\ast }=\\min _{\\mathbf {u} }\\left\\{f\\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)+J_{x}^{\\ast {\\mathsf {T}}}\\mathbf {g} \\left(\\mathbf {x} (t),\\mathbf {u} (t),t\\right)\\right\\}}', 'Characteristics': "Also some text from wikipedia:\r\nn economics, the objective is generally to maximize (rather than minimize) some dynamic social welfare function. In Ramsey's problem, this function relates amounts of consumption to levels of utility. Loosely speaking, the planner faces the trade-off between contemporaneous consumption and future consumption (via investment in capital stock that is used in production), known as intertemporal choice. Future consumption is discounted at a constant rate {\\displaystyle \\beta \\in (0,1)} {\\displaystyle \\beta \\in (0,1)}. A discrete approximation to the transition equation of capital is given by\r\n\r\n{\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}} {\\displaystyle k_{t+1}={\\hat {g}}\\left(k_{t},c_{t}\\right)=f(k_{t})-c_{t}}\r\nwhere {\\displaystyle c} c is consumption, {\\displaystyle k} k is capital, and {\\displaystyle f} f is a production function satisfying the Inada conditions. An initial capital stock {\\displaystyle k_{0}>0} {\\displaystyle k_{0}>0} is assumed.\r\n\r\nLet {\\displaystyle c_{t}} c_{t} be consumption in period t, and assume consumption yields utility {\\displaystyle u(c_{t})=\\ln(c_{t})} u(c_{t})=\\ln(c_{t}) as long as the consumer lives. Assume the consumer is impatient, so that he discounts future utility by a factor b each period, where {\\displaystyle 0<b<1} 0<b<1. Let {\\displaystyle k_{t}} k_{t} be capital in period t. Assume initial capital is a given amount {\\displaystyle k_{0}>0} k_{0}>0, and suppose that this period's capital and consumption determine next period's capital as {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}} k_{t+1}=Ak_{t}^{a}-c_{t}, where A is a positive constant and {\\displaystyle 0<a<1} 0<a<1. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows:\r\n\r\n{\\displaystyle \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t})} \\max \\sum _{t=0}^{T}b^{t}\\ln(c_{t}) subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0 for all {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T\r\nWritten this way, the problem looks complicated, because it involves solving for all the choice variables {\\displaystyle c_{0},c_{1},c_{2},\\ldots ,c_{T}} c_{0},c_{1},c_{2},\\ldots ,c_{T}. (Note that {\\displaystyle k_{0}} k_{0} is not a choice variable—the consumer's initial capital is taken as given.)\r\n\r\nThe dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of value functions {\\displaystyle V_{t}(k)} V_{t}(k), for {\\displaystyle t=0,1,2,\\ldots ,T,T+1} t=0,1,2,\\ldots ,T,T+1 which represent the value of having any amount of capital k at each time t. Note that {\\displaystyle V_{T+1}(k)=0} V_{T+1}(k)=0, that is, there is (by assumption) no utility from having capital after death.\r\n\r\nThe value of any quantity of capital at any previous time can be calculated by backward induction using the Bellman equation. In this problem, for each {\\displaystyle t=0,1,2,\\ldots ,T} t=0,1,2,\\ldots ,T, the Bellman equation is\r\n\r\n{\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} {\\displaystyle V_{t}(k_{t})\\,=\\,\\max \\left(\\ln(c_{t})+bV_{t+1}(k_{t+1})\\right)} subject to {\\displaystyle k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0} k_{t+1}=Ak_{t}^{a}-c_{t}\\geq 0\r\nThis problem is much simpler than the one we wrote down before, because it involves only two decision variables, {\\displaystyle c_{t}} c_{t} and {\\displaystyle k_{t+1}} k_{t+1}. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time t, his current capital {\\displaystyle k_{t}} k_{t} is given, and he only needs to choose current consumption {\\displaystyle c_{t}} c_{t} and saving {\\displaystyle k_{t+1}} k_{t+1}.\r\n\r\nTo actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as k. {\\displaystyle V_{T+1}(k)} V_{T+1}(k) is already known, so using the Bellman equation once we can calculate {\\displaystyle V_{T}(k)} V_{T}(k), and so on until we get to {\\displaystyle V_{0}(k)} V_{0}(k), which is the value of the initial decision problem for the whole lifetime. In other words, once we know {\\displaystyle V_{T-j+1}(k)} V_{T-j+1}(k), we can calculate {\\displaystyle V_{T-j}(k)} V_{T-j}(k), which is the maximum of {\\displaystyle \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j})} \\ln(c_{T-j})+bV_{T-j+1}(Ak^{a}-c_{T-j}), where {\\displaystyle c_{T-j}} c_{T-j} is the choice variable and {\\displaystyle Ak^{a}-c_{T-j}\\geq 0} Ak^{a}-c_{T-j}\\geq 0.\r\n\r\nWorking backwards, it can be shown that the value function at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}} V_{T-j}(k)\\,=\\,a\\sum _{i=0}^{j}a^{i}b^{i}\\ln k+v_{T-j}\r\nwhere each {\\displaystyle v_{T-j}} v_{T-j} is a constant, and the optimal amount to consume at time {\\displaystyle t=T-j} t=T-j is\r\n\r\n{\\displaystyle c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}} c_{T-j}(k)\\,=\\,{\\frac {1}{\\sum _{i=0}^{j}a^{i}b^{i}}}Ak^{a}\r\nwhich can be simplified to\r\n\r\n{\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}} {\\displaystyle {\\begin{aligned}c_{T}(k)&=Ak^{a}\\\\c_{T-1}(k)&={\\frac {Ak^{a}}{1+ab}}\\\\c_{T-2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}}}\\\\&\\dots \\\\c_{2}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}}}\\\\c_{1}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}}}\\\\c_{0}(k)&={\\frac {Ak^{a}}{1+ab+a^{2}b^{2}+\\ldots +a^{T-2}b^{T-2}+a^{T-1}b^{T-1}+a^{T}b^{T}}}\\end{aligned}}}", 'Photo': 'uploads/avengers_infinity_war_4k_8k_2.jpg', 'Price': 1000}, {'Id': 15, 'Name': 'test item2', 'Category_id': '2', 'Description': 'Description', 'Characteristics': 'Characteristics', 'Photo': 'uploads/avengers_infinity_war_iron_man_spider_man_doctor_strange_4k-3840x2160.jpg', 'Price': 10000}]
2019-05-05 16:01:22,315 translate: {1: 'Category', 2: 'test category', 3: 'test ', 4: 'test category2'}
